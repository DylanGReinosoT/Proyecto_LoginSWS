import cv2
import numpy as np
import os
import uuid
from datetime import datetime
from pathlib import Path
from fastapi import HTTPException, status
import mediapipe as mp
import face_recognition
from PIL import Image
import io
from ultralytics import YOLO


class FacialRecognitionService:
    """
    Servicio para manejar captura, almacenamiento y verificaci√≥n de rostros
    """
    
    def __init__(self):
        # Directorio base para guardar rostros - debe estar en app/facial_data
        self.FACIAL_DATA_DIR = Path(__file__).parent.parent / "facial_data"
        
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        
        # Cargar modelo YOLO para detecci√≥n de accesorios (liveness)
        try:
            self.yolo_model = YOLO('yolov8n.pt')  # Modelo nano para detecci√≥n r√°pida
            print("[LOG] Modelo YOLO cargado exitosamente")
        except Exception as e:
            print(f"[WARN] Error cargando YOLO: {e}. Liveness detection deshabilitada")
            self.yolo_model = None
        
        # Crear directorio si no existe
        self.FACIAL_DATA_DIR.mkdir(parents=True, exist_ok=True)
        print(f"[LOG] Directorio facial_data creado en: {self.FACIAL_DATA_DIR}")
    
    @staticmethod
    def ensure_facial_data_dir():
        """Asegura que el directorio de datos faciales existe"""
        facial_data_dir = Path(__file__).parent.parent / "facial_data"
        facial_data_dir.mkdir(parents=True, exist_ok=True)
    
    def save_facial_image(self, image_data: bytes, user_id: str) -> str:
        """
        Guarda una imagen facial para un usuario
        
        Args:
            image_data: Datos de imagen en bytes
            user_id: ID del usuario
            
        Returns:
            Ruta del archivo guardado
            
        Raises:
            HTTPException: Si hay error al guardar
        """
        try:
            # Crear directorio del usuario si no existe
            user_facial_dir = self.FACIAL_DATA_DIR / user_id
            user_facial_dir.mkdir(exist_ok=True)
            
            # Convertir bytes a imagen numpy
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Imagen inv√°lida"
                )
            
            # Generar nombre √∫nico para la imagen
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"face_{timestamp}.jpg"
            filepath = user_facial_dir / filename
            
            # Guardar imagen
            cv2.imwrite(str(filepath), image)
            
            return str(filepath)
        
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error guardando imagen: {str(e)}"
            )
    
    def detect_face_in_image(self, image_data: bytes) -> dict:
        """
        Detecta si hay un rostro en la imagen
        
        Args:
            image_data: Datos de imagen en bytes
            
        Returns:
            Diccionario con informaci√≥n del rostro detectado
            
        Raises:
            HTTPException: Si no se detecta un rostro
        """
        try:
            # Convertir bytes a imagen numpy
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Imagen inv√°lida"
                )
            
            # Detectar rostro
            with self.mp_face_detection.FaceDetection(
                model_selection=0,
                min_detection_confidence=0.5
            ) as face_detection:
                
                rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                results = face_detection.process(rgb_image)
                
                if not results.detections:
                    raise HTTPException(
                        status_code=status.HTTP_400_BAD_REQUEST,
                        detail="No se detect√≥ rostro en la imagen"
                    )
                
                # Obtener informaci√≥n del primer rostro detectado
                detection = results.detections[0]
                h, w, _ = image.shape
                
                bboxC = detection.location_data.relative_bounding_box
                bbox = {
                    "x": int(bboxC.xmin * w),
                    "y": int(bboxC.ymin * h),
                    "width": int(bboxC.width * w),
                    "height": int(bboxC.height * h),
                    "confidence": float(detection.score[0])
                }
                
                return {
                    "face_detected": True,
                    "bbox": bbox,
                    "message": "Rostro detectado correctamente"
                }
        
        except HTTPException:
            raise
        except Exception as e:
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error detectando rostro: {str(e)}"
            )
    
    def get_user_facial_images(self, user_id: str) -> list:
        """
        Obtiene todas las im√°genes faciales de un usuario
        
        Args:
            user_id: ID del usuario
            
        Returns:
            Lista de rutas de im√°genes
        """
        user_facial_dir = self.FACIAL_DATA_DIR / user_id
        
        if not user_facial_dir.exists():
            return []
        
        images = []
        for file in user_facial_dir.glob("face_*.jpg"):
            images.append(str(file))
        
        return sorted(images, reverse=True)  # M√°s recientes primero
    
    def verify_face(self, image_data: bytes, user_id: str) -> dict:
        """
        Verifica si el rostro en la imagen coincide con el registrado para un usuario espec√≠fico
        
        Usa face_recognition para comparaci√≥n precisa de faces
        
        Args:
            image_data: Datos de imagen a verificar
            user_id: ID del usuario a verificar
            
        Returns:
            Resultado de la verificaci√≥n
        """
        try:
            # Verificar que el usuario tenga im√°genes guardadas
            user_images = self.get_user_facial_images(user_id)
            
            if not user_images:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="No tiene rostro registrado. Por favor, registre su rostro primero en el perfil."
                )
            
            # Detectar rostro en la imagen actual
            detection_result = self.detect_face_in_image(image_data)
            
            if not detection_result["face_detected"]:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="‚ùå No se detect√≥ rostro en la imagen. Aseg√∫rese de estar mirando a la c√°mara."
                )
            
            # Verificar liveness (evitar fotos/pantallas/dispositivos)
            liveness_check = self._check_liveness(image_data)
            if not liveness_check["is_alive"]:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail=liveness_check['reason']
                )
            
            # Comparar con im√°genes registradas usando face_recognition
            verification_result = self._compare_faces(image_data, user_images)
            
            # ‚úÖ VERIFICACI√ìN IMPORTANTE: El rostro debe coincidir con el del usuario
            if verification_result["match"]:
                return {
                    "verified": True,
                    "message": "‚úÖ Rostro verificado correctamente. Acceso permitido.",
                    "confidence": verification_result["confidence"],
                    "liveness": liveness_check
                }
            else:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="‚ùå El rostro no coincide con el registrado. Intente de nuevo."
                )
        
        except HTTPException:
            raise
        except Exception as e:
            print(f"[ERROR] verify_face: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=f"Error verificando rostro: {str(e)}"
            )
    
    def verify_face_for_login(self, image_data: bytes, user_id: str) -> dict:
        """
        Verifica el rostro durante el login - Versi√≥n estricta
        
        ‚ö†Ô∏è IMPORTANTE: Esta verificaci√≥n es OBLIGATORIA para login
        - Compara rostro solo con el usuario espec√≠fico
        - Falla si el rostro no pertenece a ese usuario
        - Falla si el usuario no tiene rostro registrado
        
        Args:
            image_data: Datos de imagen a verificar
            user_id: ID del usuario que intenta hacer login
            
        Returns:
            Dict con:
            - verified: True si verificaci√≥n exitosa
            - message: Mensaje descriptivo
            - confidence: Confianza de la verificaci√≥n
        """
        try:
            # Verificar que el usuario tenga facial recognition habilitado
            from app.database import db
            user_doc = db.collection("users").document(user_id).get()
            
            if not user_doc.exists:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="‚ùå Usuario no encontrado"
                )
            
            user_data = user_doc.to_dict()
            facial_enabled = user_data.get("facial_recognition_enabled", False)
            
            # Si el usuario tiene facial recognition habilitado, es OBLIGATORIO verificarlo
            if not facial_enabled:
                raise HTTPException(
                    status_code=status.HTTP_403_FORBIDDEN,
                    detail="‚ùå Facial recognition no habilitado para este usuario"
                )
            
            # Obtener im√°genes del usuario
            user_images = self.get_user_facial_images(user_id)
            
            if not user_images:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="‚ùå No hay rostro registrado para este usuario. No se puede completar el login."
                )
            
            # Detectar rostro en la imagen actual
            try:
                detection_result = self.detect_face_in_image(image_data)
                
                if not detection_result["face_detected"]:
                    raise HTTPException(
                        status_code=status.HTTP_401_UNAUTHORIZED,
                        detail="‚ùå No se detect√≥ un rostro v√°lido en la imagen."
                    )
            except HTTPException:
                raise
            except Exception as e:
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail=f"‚ùå Error detectando rostro: {str(e)}"
                )
            
            # Verificar liveness (detecci√≥n de dispositivos, accesorios, etc.)
            liveness_check = self._check_liveness(image_data)
            if not liveness_check["is_alive"]:
                # ‚ö†Ô∏è SEGURIDAD CR√çTICA: Rechazar si no pasa validaci√≥n de liveness
                security_level = liveness_check.get("security_level", "DESCONOCIDO")
                print(f"[üö´ SEGURIDAD {security_level}] Liveness check fallido: {liveness_check['reason']}")
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail=liveness_check['reason']
                )
            
            # ‚úÖ VERIFICACI√ìN CR√çTICA: Comparar rostro SOLO con el usuario espec√≠fico
            verification_result = self._compare_faces(image_data, user_images)
            
            if not verification_result["match"]:
                # ‚ö†Ô∏è SEGURIDAD: El rostro no coincide - RECHAZAR login
                raise HTTPException(
                    status_code=status.HTTP_401_UNAUTHORIZED,
                    detail="‚ùå El rostro no pertenece a este usuario. Acceso denegado."
                )
            
            # ‚úÖ √âXITO: Todo verificado correctamente
            return {
                "verified": True,
                "message": "‚úÖ Identidad verificada. Login exitoso.",
                "confidence": verification_result["confidence"],
                "user_id": user_id
            }
        
        except HTTPException:
            raise
        except Exception as e:
            print(f"[ERROR] verify_face_for_login: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail=f"‚ùå Error en verificaci√≥n facial: {str(e)}"
            )
    
    def _compare_faces(self, image_data: bytes, registered_images: list) -> dict:
        """
        Compara el rostro actual con los rostros registrados del usuario
        
        ‚ö†Ô∏è CR√çTICO: Esta funci√≥n SOLO se llama si:
        1. El usuario EXISTE
        2. El usuario TIENE facial recognition habilitado
        3. El usuario TIENE al menos un rostro registrado (no_images > 0)
        
        Args:
            image_data: Imagen a verificar en bytes
            registered_images: Lista de rutas de im√°genes registradas del usuario
            
        Returns:
            Dict con resultado de comparaci√≥n y confianza
            - match: True/False
            - confidence: Porcentaje de similitud
            - distance: Valor num√©rico (menor = m√°s similar)
            - matched_images: Cu√°ntas im√°genes registradas coincidieron
        """
        try:
            # VALIDACI√ìN CR√çTICA: Verificar que hay im√°genes registradas
            if not registered_images or len(registered_images) == 0:
                print("[CRITICAL] VULNERABILIDAD: Se intent√≥ comparar con lista vac√≠a")
                return {
                    "match": False,
                    "confidence": 0,
                    "distance": 1.0,
                    "matched_images": 0,
                    "reason": "No hay im√°genes registradas para comparar"
                }
            
            # Convertir bytes a imagen
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                print("[ERROR] Imagen capturada es inv√°lida")
                return {
                    "match": False,
                    "confidence": 0,
                    "distance": 1.0,
                    "matched_images": 0,
                    "reason": "Imagen inv√°lida"
                }
            
            # Convertir BGR a RGB para face_recognition
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Obtener encoding del rostro actual
            try:
                current_face_encodings = face_recognition.face_encodings(image_rgb)
                if not current_face_encodings:
                    print("[ERROR] No se pudo extraer encoding del rostro capturado")
                    return {
                        "match": False,
                        "confidence": 0,
                        "distance": 1.0,
                        "matched_images": 0,
                        "reason": "No se pudo extraer caracter√≠sticas del rostro"
                    }
                
                current_face_encoding = current_face_encodings[0]
            except Exception as e:
                print(f"[ERROR] Error obteniendo encoding del rostro actual: {e}")
                return {
                    "match": False,
                    "confidence": 0,
                    "distance": 1.0,
                    "matched_images": 0,
                    "reason": f"Error procesando rostro: {str(e)}"
                }
            
            # COMPARACI√ìN ESTRICTA: Comparar con CADA imagen registrada
            best_match = False
            best_distance = 1.0
            matched_count = 0
            match_details = []
            
            # Threshold para considerar un match: 0.55 (m√°s estricto que 0.6)
            DISTANCE_THRESHOLD = 0.55
            CONFIDENCE_MIN = 35  # Confianza m√≠nima requerida (%)
            
            print(f"[LOG] Comparando rostro capturado con {len(registered_images)} im√°genes registradas")
            
            for idx, registered_image_path in enumerate(registered_images):
                try:
                    # Cargar imagen registrada
                    registered_image = face_recognition.load_image_file(registered_image_path)
                    registered_face_encodings = face_recognition.face_encodings(registered_image)
                    
                    if not registered_face_encodings:
                        print(f"[WARN] No se pudo extraer encoding de imagen registrada #{idx + 1}")
                        continue
                    
                    registered_face_encoding = registered_face_encodings[0]
                    
                    # Comparar faces usando distancia euclidiana
                    distance = face_recognition.face_distance(
                        [registered_face_encoding],
                        current_face_encoding
                    )[0]
                    
                    # Calcular confianza
                    confidence = max(0, (1 - distance) * 100)
                    
                    print(f"[LOG] Imagen #{idx + 1}: distance={distance:.4f}, confidence={confidence:.1f}%")
                    
                    match_details.append({
                        "image": registered_image_path,
                        "distance": float(distance),
                        "confidence": float(confidence),
                        "is_match": distance < DISTANCE_THRESHOLD
                    })
                    
                    # Evaluar si es coincidencia: distancia < threshold
                    if distance < DISTANCE_THRESHOLD and confidence >= CONFIDENCE_MIN:
                        best_match = True
                        matched_count += 1
                        best_distance = min(best_distance, distance)
                        print(f"[‚úì] COINCIDENCIA ENCONTRADA en imagen #{idx + 1} con confidence {confidence:.1f}%")
                    
                except Exception as e:
                    print(f"[ERROR] Error procesando imagen registrada #{idx + 1}: {e}")
                    continue
            
            # RESULTADO FINAL: Requerir al menos UNA coincidencia
            if best_match and matched_count > 0:
                confidence = max(0, (1 - best_distance) * 100)
                print(f"[‚úì‚úì‚úì] VERIFICACI√ìN EXITOSA: {matched_count}/{len(registered_images)} im√°genes coincidieron")
                return {
                    "match": True,
                    "confidence": float(confidence),
                    "distance": float(best_distance),
                    "matched_images": matched_count,
                    "total_images": len(registered_images),
                    "reason": f"Rostro coincide con {matched_count}/{len(registered_images)} im√°genes registradas"
                }
            else:
                print(f"[‚úó‚úó‚úó] VERIFICACI√ìN FALLIDA: Ninguna imagen coincidi√≥")
                return {
                    "match": False,
                    "confidence": 0,
                    "distance": float(best_distance),
                    "matched_images": 0,
                    "total_images": len(registered_images),
                    "reason": f"El rostro no coincide con ninguna de las {len(registered_images)} im√°genes registradas",
                    "details": match_details  # Para debugging
                }
        
        except Exception as e:
            print(f"[CRITICAL ERROR] _compare_faces: {str(e)}")
            return {
                "match": False,
                "confidence": 0,
                "distance": 1.0,
                "matched_images": 0,
                "reason": f"Error cr√≠tico en comparaci√≥n: {str(e)}"
            }
    
    def _check_liveness(self, image_data: bytes) -> dict:
        """
        Verifica que sea una persona viva (no una foto/pantalla/dispositivo)
        
        ‚ö†Ô∏è VALIDACIONES CR√çTICAS:
        1. Detecta pantallas, monitores, TVs, celulares, tablets
        2. Detecta si el rostro est√° siendo mostrado EN un dispositivo
        3. Rechaza accesorios sospechosos (gafas, sombreros, m√°scaras)
        4. Rechaza si hay objetos adicionales cerca del rostro
        
        Args:
            image_data: Imagen a verificar en bytes
            
        Returns:
            Dict con resultado de verificaci√≥n
            - is_alive: True/False
            - reason: Descripci√≥n del resultado
            - devices_detected: Dispositivos encontrados (si los hay)
        """
        try:
            if not self.yolo_model:
                # Si YOLO no est√° disponible, permitir de todos modos
                return {
                    "is_alive": True,
                    "reason": "YOLO no disponible - liveness check omitido",
                    "devices_detected": []
                }
            
            # Convertir bytes a imagen
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {
                    "is_alive": False, 
                    "reason": "‚ùå Imagen inv√°lida",
                    "devices_detected": []
                }
            
            # Ejecutar YOLO para detecci√≥n de objetos
            results = self.yolo_model(image, verbose=False)
            
            if not results or len(results) == 0:
                return {
                    "is_alive": True, 
                    "reason": "‚úÖ Sin objetos sospechosos detectados",
                    "devices_detected": []
                }
            
            # ============================================
            # CLASES COCO - Mapeo de dispositivos peligrosos
            # ============================================
            # Dispositivos donde se podr√≠a mostrar un rostro (M√ÅS PELIGROSO)
            device_classes = {
                62: "laptop",        # Pantalla de laptop
                63: "tv",            # Televisor
                65: "remote",        # Control remoto (indica pantalla cercana)
                73: "book",          # Podr√≠a ser un libro/papel con foto
                74: "cell phone",    # Celular/tel√©fono
            }
            
            # Accesorios que ocultan/alteran el rostro
            accessory_classes = {
                0: "person",         # Persona - puede usarse para bloquear vista
                27: "tie",           # Corbata cerca del rostro
                28: "cake",          # Objeto frente al rostro
                29: "couch",         # Indicativo de ambiente controlado
                30: "potted plant",  # Objeto grande que podr√≠a ocluir
            }
            
            # Accesorios PERMITIDOS (lentes, gafas no son problema)
            allowed_accessories = {
                37: "glasses",       # ‚úÖ PERMITIDO - Lentes/gafas normales
                38: "sunglasses",    # ‚úÖ PERMITIDO - Gafas de sol (levemente sospechosas)
                39: "goggles",       # ‚úÖ PERMITIDO - Gafas de protecci√≥n
            }
            
            # Objetos sospechosos adicionales
            suspicious_classes = {
                34: "bottle",        # Botellas para ocultar rostro
                35: "wine glass",    # Cristaler√≠a
                36: "cup",           # Taza/vaso
                42: "spoon",         # Utensilio
                43: "bowl",          # Recipiente
                44: "banana",        # Objeto para ocluir
                45: "apple",         # Objeto para ocluir
                47: "sandwich",      # Objeto frente rostro
                48: "orange",        # Objeto para ocluir
                50: "pizza",         # Objeto grande
                51: "donut",         # Objeto frente rostro
                52: "cake",          # Objeto grande
            }
            
            # M√°scara facial expl√≠cita (muy peligrosa)
            mask_classes = {
                0: "mask",           # M√°scara (si el modelo la detecta)
            }
            
            detected_devices = []
            detected_accessories = []
            detected_suspicious = []
            detected_allowed_accessories = []  # Lentes, gafas (permitidas)
            device_detections = []  # Para guardar detalles de dispositivos
            
            print("[LOG] ========== AN√ÅLISIS YOLO ==========")
            
            for result in results:
                if result.boxes:
                    for box in result.boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        
                        # Obtener coordenadas del bounding box
                        x1, y1, x2, y2 = box.xyxy[0]
                        box_width = float(x2 - x1)
                        box_height = float(y2 - y1)
                        box_area = box_width * box_height
                        
                        # Imagen total
                        img_height, img_width = image.shape[:2]
                        img_area = img_height * img_width
                        box_percentage = (box_area / img_area) * 100
                        
                        # Verificar si son LENTES PERMITIDOS
                        if class_id in allowed_accessories:
                            accessory_name = allowed_accessories[class_id]
                            detected_allowed_accessories.append(accessory_name)
                            print(f"[‚úÖ PERMITIDO] {accessory_name.upper()} detectado - Aceptado")
                        
                        # Verificar si es un DISPOSITIVO (critial)
                        elif class_id in device_classes:
                            device_name = device_classes[class_id]
                            detected_devices.append(device_name)
                            device_detections.append({
                                "type": device_name,
                                "confidence": float(confidence),
                                "size_percentage": round(box_percentage, 2),
                                "position": {
                                    "x1": float(x1), "y1": float(y1),
                                    "x2": float(x2), "y2": float(y2)
                                }
                            })
                            print(f"[‚ö†Ô∏è DEVICE] {device_name.upper()} detectado con {confidence:.2%} confianza (ocupa {box_percentage:.1f}% de la imagen)")
                        
                        # Verificar accesorios
                        elif class_id in accessory_classes:
                            accessory_name = accessory_classes[class_id]
                            detected_accessories.append(accessory_name)
                            print(f"[‚ö†Ô∏è ACCESORIO] {accessory_name} detectado")
                        
                        # Verificar objetos sospechosos
                        elif class_id in suspicious_classes:
                            suspicious_name = suspicious_classes[class_id]
                            detected_suspicious.append(suspicious_name)
                            print(f"[‚ö†Ô∏è SOSPECHOSO] {suspicious_name} detectado")
            
            print("[LOG] ====================================")
            
            # ============================================
            # L√ìGICA DE DECISI√ìN - RECHAZO ESTRICTO
            # ============================================
            
            # üö´ RECHAZAR SI: Se detecta dispositivo (pantalla, TV, tel√©fono, tablet)
            if detected_devices:
                devices_str = ", ".join(detected_devices)
                print(f"[‚ùå RECHAZO] Se detect√≥ dispositivo de video: {devices_str}")
                return {
                    "is_alive": False,
                    "reason": f"‚ùå VERIFICACI√ìN FALLIDA: Se detect√≥ un dispositivo de pantalla ({devices_str}). El rostro debe presentarse directamente, no a trav√©s de una pantalla, tel√©fono, tablet o monitor.",
                    "devices_detected": device_detections,
                    "security_level": "CR√çTICO"
                }
            
            # üö´ RECHAZAR SI: Hay m√∫ltiples accesorios sospechosos (NO incluye lentes)
            if len(detected_accessories) >= 2:
                accessories_str = ", ".join(detected_accessories)
                print(f"[‚ùå RECHAZO] M√∫ltiples accesorios detectados: {accessories_str}")
                return {
                    "is_alive": False,
                    "reason": f"‚ùå VERIFICACI√ìN FALLIDA: Demasiados accesorios/objetos detectados ({accessories_str}). Presente su rostro sin accesorios adicionales.",
                    "devices_detected": [],
                    "security_level": "ALTO"
                }
            
            # ‚úÖ PERMITIR SI: Solo hay lentes/gafas (sin otros accesorios)
            if detected_allowed_accessories and not detected_accessories and not detected_suspicious:
                glasses_str = ", ".join(detected_allowed_accessories)
                print(f"[‚úÖ PERMITIDO] Rostro con lentes/gafas: {glasses_str}")
                return {
                    "is_alive": True,
                    "reason": f"‚úÖ Verificaci√≥n de liveness exitosa. Rostro con {glasses_str} aceptado.",
                    "devices_detected": [],
                    "security_level": "BAJO",
                    "note": f"Usuario lleva {glasses_str}"
                }
            
            # ‚ö†Ô∏è ADVERTENCIA SI: Hay objetos sospechosos O lentes + otros objetos
            if detected_suspicious or detected_accessories:
                warnings = detected_suspicious + detected_accessories
                # Si hay lentes pero tambi√©n otros objetos
                if detected_allowed_accessories:
                    warnings.extend(detected_allowed_accessories)
                warnings_str = ", ".join(warnings)
                print(f"[‚ö†Ô∏è ADVERTENCIA] Objetos detectados: {warnings_str}")
                return {
                    "is_alive": True,  # Permitir, pero registrar
                    "reason": f"‚ö†Ô∏è ADVERTENCIA: Se detectaron objetos ({warnings_str}). Imagen aceptada pero verificada con objetos presentes.",
                    "devices_detected": [],
                    "security_level": "MEDIO",
                    "warnings": warnings
                }
            
            # ‚úÖ ACEPTAR: Todo est√° bien
            return {
                "is_alive": True,
                "reason": "‚úÖ Verificaci√≥n de liveness exitosa. Rostro v√°lido detectado.",
                "devices_detected": [],
                "security_level": "BAJO"
            }
        
        except Exception as e:
            print(f"[ERROR] Error en _check_liveness: {e}")
            # En caso de error, RECHAZAR por seguridad
            return {
                "is_alive": False,
                "reason": f"‚ùå Error en verificaci√≥n de liveness: {str(e)}",
                "devices_detected": [],
                "security_level": "ERROR"
            }
    
    def check_facial_uniqueness(self, image_data: bytes, exclude_user_id: str = None) -> dict:
        """
        Verifica si un rostro ya existe en el sistema (en otros usuarios)
        
        Se usa durante el registro para asegurar que cada rostro sea √∫nico.
        
        Args:
            image_data: Imagen a verificar en bytes
            exclude_user_id: ID del usuario a excluir (para no compararse a s√≠ mismo)
            
        Returns:
            Dict con:
            - is_unique: True si el rostro no existe en otros usuarios
            - message: Mensaje descriptivo
            - matched_user_id: ID del usuario si se encontr√≥ coincidencia (None si es √∫nico)
            - confidence: Confianza de la coincidencia si existe
        """
        try:
            # Obtener todos los directorios de usuarios
            if not self.FACIAL_DATA_DIR.exists():
                return {
                    "is_unique": True,
                    "message": "No hay usuarios registrados a√∫n",
                    "matched_user_id": None,
                    "confidence": 0
                }
            
            # Convertir bytes a imagen para obtener encoding
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail="Imagen inv√°lida"
                )
            
            # Convertir BGR a RGB para face_recognition
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Obtener encoding del rostro actual
            try:
                current_face_encodings = face_recognition.face_encodings(image_rgb)
                if not current_face_encodings:
                    raise Exception("No se detect√≥ un rostro v√°lido en la imagen")
                current_encoding = current_face_encodings[0]
            except Exception as e:
                return {
                    "is_unique": False,
                    "message": f"Error procesando imagen: {str(e)}",
                    "matched_user_id": None,
                    "confidence": 0
                }
            
            # Recorrer todos los usuarios registrados
            for user_dir in self.FACIAL_DATA_DIR.iterdir():
                if not user_dir.is_dir():
                    continue
                
                user_id = user_dir.name
                
                # Excluir el usuario actual si se especifica
                if exclude_user_id and user_id == exclude_user_id:
                    continue
                
                # Obtener im√°genes del usuario
                user_images = list(user_dir.glob("face_*.jpg"))
                
                if not user_images:
                    continue
                
                # Comparar con la primera imagen del usuario
                # (o todas si quieres ser m√°s exhaustivo)
                registered_image_path = user_images[0]
                
                try:
                    registered_image = face_recognition.load_image_file(str(registered_image_path))
                    registered_encodings = face_recognition.face_encodings(registered_image)
                    
                    if not registered_encodings:
                        continue
                    
                    registered_encoding = registered_encodings[0]
                    
                    # Comparar distancia euclidiana
                    distance = np.linalg.norm(current_encoding - registered_encoding)
                    
                    # Si la distancia es muy peque√±a (< 0.6), es una coincidencia
                    DISTANCE_THRESHOLD = 0.6
                    if distance < DISTANCE_THRESHOLD:
                        confidence = max(0, (1 - distance) * 100)
                        return {
                            "is_unique": False,
                            "message": f"El rostro ya est√° registrado por otro usuario",
                            "matched_user_id": user_id,
                            "confidence": round(confidence, 2)
                        }
                
                except Exception as e:
                    print(f"[WARN] Error comparando con usuario {user_id}: {str(e)}")
                    continue
            
            # Si llegamos aqu√≠, el rostro es √∫nico
            return {
                "is_unique": True,
                "message": "El rostro es √∫nico en el sistema",
                "matched_user_id": None,
                "confidence": 0
            }
        
        except HTTPException:
            raise
        except Exception as e:
            print(f"[ERROR] check_facial_uniqueness: {str(e)}")
            return {
                "is_unique": False,
                "message": f"Error verificando unicidad del rostro: {str(e)}",
                "matched_user_id": None,
                "confidence": 0
            }
